#+TITLE: HDF5 Introduction
#+AUTHOR: Gerd Heber
#+EMAIL: gheber@hdfgroup.org
#+CREATOR: <a href="http://www.gnu.org/software/emacs/">Emacs</a> 27.1.90 (<a href="http://orgmode.org">Org</a> mode 9.4.4)
#+DATE: [2021-01-01 Fri]
#+OPTIONS: author:t creator:t email:t toc:nil num:nil

#+PROPERTY: header-args :eval never-export

* Outline

#+begin_src plantuml :file img/outline.png :exports results
@startmindmap
scale 1
<style>
mindmapDiagram {
.orange {
BackgroundColor orange
}
.blue {
BackgroundColor lightblue
}
.green {
BackgroundColor lightgreen
}
}
</style>
+ <b>HDF5</b> <<orange>>
++ <b>The HDF Group</b>
+++_ Values
+++_ Mission
+++_ Services
++ <i>Hello, HDF5!</i>
+++_ Learning Curve
++ Data Model
+++_ Array Variables
+++_ (Multi-)Graphs
+++_ Metadata
-- Software
---_ HDF5 Library
---_ Tools
---_ HSDS
-- Ecosystem <<green>>
---_ Python, R, Julia, ...
---_ Edge (IoT), HPC, Cloud
---_ Vendors
-- Communities <<blue>>
---_ Outreach
---_ Standards
---_ Data Products
@endmindmap
#+end_src

#+RESULTS:
[[file:img/outline.png]]

* The HDF Group

Non-profit company on a mission:

#+begin_quote
/To make the management of large & complex data as simple as possible, but no
simpler./
#+end_quote

*Our values:*

- Simple data model
- Free Open Source Software
- Technical excellence
- Diverse community

* The HDF Community

It's hard to find a walk of life /not/ touched by HDF5. (Maybe literary studies?)

- Public and private sector
- Academia, government, industry
- Organizations (NASA, DOE, CEA, ITER, DESY)
- Standards bodies (OGC, EXPRESS, Allotrope, CGNS, RESQML)
- Sectors (aerospace, oil & gas, pharma, power systems, finance)
- Research (astronomy, life science, material science, ML)
- Data integrators, life cycle managers
- Developers

* Starting Point

- [[https://mitpress.mit.edu/books/raw-data-oxymoron]["Raw data" is an oxymoron]] (It needs an domain-specific /interpretive base/.)
- Data comes in many /representations/: in registers, memory, storage...
- Some data is used as /metadata/ for other data.
- Data can be "at rest" (files, objects) or transit environments (I/O)

/Data management/ is the art of:

  1. Maintaining data integrity
  2. Leaving clues for the interpretive base
  3. Removing "data friction"

* H - D - F - 5

Historically & literally: HDF5 = *H* ierarchical *D* ata *F* ormat v *5*

#+begin_quote
/The meaning of a word is its use in the language./ (Wittgenstein)
#+end_quote

Depending on your use HDF5 is:

1. A _generic_ (=not specific) data management _interface_ with a bent
   toward multi-dimensional arrays
   - HDF5 sits on the periphery
   - You get some of the benefits, e.g., portability

2. A data management _interface toolkit_.
   - HDF5 is part of the fabric
   - You create domain-specific interfaces to manage self-describing data
     representations
   - You get a streamlined /data life cycle/

HDF5-based interfaces often surpass other solutions in power, sophistication,
simplicity, performance, and portability.

** Hierarchical

Items are presented in a /hierarchically structured name space/

#+begin_src plantuml :file img/hdf5-container.png :exports results
scale 1
actor User #red
rectangle "HDF5 Container" {
card B [
    / (root)
    |_ Level 1a
      |_ Level 2a
      |_ Level 2b
      |_ Level 2c
        |_ Level 3a
      |_ Level 2d
    |_ Level 1b
      |_ Level 2e
]
}
User -> B
  #+end_src

  #+RESULTS:
  [[file:img/hdf5-container.png]]

** Data

/Complex data/ & *Metadata*

  - (Complex = consisting of interconnected or interwoven parts, composite)
  - Physical experiments & observational data
  - Simulations
  - Values of function evaluations
  - Streams

Data is "caught" in a /web of objects./ Links and nodes can be pre-defined or
user-defined items.

#+begin_src plantuml :file img/technical-detail.png :exports results
scale 1
card "/" as root
interface " " as i1a
interface " " as i1b
interface " " as i2a
queue " " as i2b
interface " " as i2c
collections " " as i2d
cloud " " as i2e
node " " as i3a
root --> i1a : "Level 1a"
i1a --> i2a : "Level 2a"
i1a --> i2b : "Level 2b"
i1a --> i2c #blue;line.dotted;text:blue : "Level 2c"
i2c --> i3a : "Level 3a"
i1a --> i2d : "Level 2d"
root --> i1b #line:red;line.bold;text:red : "Level 1b"
i1b --> i2e #green;line.dashed;text:green : "Level 2e"
    #+end_src

    #+RESULTS:
    [[file:img/technical-detail.png]]

** Format

An arrangement of data such that it can be processed or stored by a computer

Many different layouts exist for such /HDF5 containers/:
- Single file
- Multiple files
- Memory buffers
- Collection of objects in [[https://www.intel.com/content/www/us/en/high-performance-computing/daos-high-performance-storage-brief.html][Intel DAOS]] or [[https://aws.amazon.com/s3/][Amazon S3]]
- ...

And you can create your own layouts!

** (Version) 5

We've tried (in versions 1,2,3, 4) to make all original mistakes for you!

* Hello, HDF5!

The introduction to [[https://g.co/kgs/dZehBL][Andrew Collette's]] [[https://www.oreilly.com/library/view/python-and-hdf5/9781491944981/][book]]

#+ATTR_HTML: :width 300px
#+ATTR_LATEX: :width 300px
[[file:./img/Python_and_HDF5.png]]

begins with an intuitive example:

#+begin_src python -n :exports both :tangle "src/weather_station.py" :results output

import h5py, numpy as np, platform as pfm

# Weather stations record temperatures and wind speeds

with h5py.File('hello.hdf5', 'w') as f:
    f.attrs['system'] = pfm.system();
    f.attrs['release'] = pfm.release();
    f.attrs['processor'] = pfm.processor();

    # station ID 15
    temperature = np.random.random(1024)
    dt = 10.0   # Temperature sampled every 10 seconds
    wind = np.random.random(2048)
    dt_wind = 5.0   # Wind sampled every 5 seconds
    f['/15/temperature'] = temperature
    f['/15/temperature'].attrs['dt'] = dt
    f['/15/wind'] = wind
    f['/15/wind'].attrs['dt'] = dt_wind
    # station 20
    # f["/20/..."] = ...

from pathlib import Path
print('File size: {} bytes'.format(Path('hello.hdf5').stat().st_size))

#+end_src

#+RESULTS:
: File size: 32768 bytes

After running the example, we have an HDF5 file containing temperature and wind
speed time series from one or more weather stations.

* Data Model

Judging from our =Hello, HDF5!= example, we are dealing with nested /groupings of
arrays/.  There's one grouping for each weather station and there are two array
variables (=temperature= and =wind=) per grouping. This is almost accurate, except
that all weather station groupings are part of the so-called /root group/, and
that there are additional decorations (system characteristics, sampling rates).

#+begin_src plantuml :file img/hello-hdf5.png :exports results
scale 1
actor User #red
rectangle "HDF5 Container" {
card B [
    / (root)
    |_ 15
      |_ temperature
      |_ wind
    |_ 20
      |_ ...
]
}
User -> B
  #+end_src

  #+RESULTS:
  [[file:img/hello-hdf5.png]]

For the purpose of this introduction, it's OK to think of an HDF5 container as a
/file system in a file/. (Of course, as long as there is a file...)

Speaking informally, the HDF5 data model includes /two primitives/ and a set of
combination rules. HDF5 is about describing array variables and their
relationships.

#+begin_src plantuml :file img/hdf5-primitives.png :exports results
scale 1.5
skinparam rectangle {
    roundCorner<<Concept>> 25
}

rectangle "Array Variable" <<Concept>> {
  artifact " attribute "
  node "datset"
}

rectangle "Grouping" <<Concept>> {
  folder "group"
}
#+end_src

#+RESULTS:
[[file:img/hdf5-primitives.png]]

(Datasets and attributes are /roles/ in which array variables can be used in HDF5,
and different rules apply to them.)

* Ecosystem

** Language bindings

- It's hard to find a language for which there are no HDF5 bindings or an API
- The HDF Group develops and maintains a reference implementation in C and
  bindings for Fortran
- The community provides excellent bindings for Python, R, C++, Julia, .NET,
  Java...
- Third parties support HDF5 in their products, e.g., MathWorks, National
  Instruments, Wolfram, etc.

** IoT / Edge

Download a fully featured Python 3 IDE to your mobile device from the [[https://play.google.com/store/apps/details?id=ru.iiec.pydroid3][Google
Play store]].

#+ATTR_HTML: :width 480px
#+ATTR_LATEX: :width 480px
[[file:./img/Pydroid3.png]]

*Homework:* Run the ="Hello, HDF5!"= example on your phone and look at the file
on your computer!

** HPC (aka. Parallel HDF5) <<sec:hpc>>

 Below we illustrate how to transition from a single process writing to a
 dataset to multiple MPI-processes writing to different parts of a single
 dataset in a single shared HDF5 file. The code is written to emphasize
 similarities and to highlight the few places where they differ. The common
 portions are shown in the [[sec:boilerplate][appendix]].

*** A single process writing to a single dataset

The basic flow is as follows:
1. Create an HDF5 file (line [[(seq-fcrt)]])
2. Create an HDF5 dataset (line [[(seq-dcrt)]])
3. Select the destination in the file (line [[(seq-sel)]])
4. Write a data buffer  (line [[(seq-wrt)]])

#+headers: :flags "-I./src" :libs -lhdf5 :exports code
#+begin_src C -r -n :tangle src/hdf5-101.c :noweb no-export :results silent

#include "literate-hdf5.h"
#define SIZE 1024*1024

int main(int argc, char** argv)
{
  hid_t fapl, file, dset, file_space, mem_space;
  float* buffer;
  hsize_t file_size;

  fapl = H5Pcreate(H5P_FILE_ACCESS);
  file = H5Fcreate("single-proc.h5", H5F_ACC_TRUNC, H5P_DEFAULT,
                   fapl); // (ref:seq-fcrt)

  dset = (*
          <<make-dataset>>) (file, "1Mi-floats", SIZE); // (ref:seq-dcrt)
  file_space = H5Dget_space(dset);
  H5Sselect_all(file_space);  // (ref:seq-sel)

  <<create-buffer-and-write>> // (ref:seq-wrt)

  <<clean-up>>
}

#+end_src

*** Multiple MPI processes writing to a single dataset in a shared file

The basic flow is exactly the same as in the sequential case:
1. Create an HDF5 file (line [[(par-fcrt)]])
2. Create an HDF5 dataset (line [[(par-dcrt)]])
3. Select the destination in the file (lines [[(par-sel1)]] - [[(par-sel2)]])
4. Write a data buffer  (line [[(par-wrt)]])

There are only two differences between the sequential case and the MPI-parallel
case:
1. We have to instruct the HDF5 library to use MPI-IO layer (line [[(par-fapl)]])
2. Since the data buffers from different MPI ranks are destined for different
   "offsets" in the dataset, the selection process is rank dependent (lines
   [[(par-sel1)]] - [[(par-sel2)]])

/That's it./ Everything else is the same. Most importantly:

#+begin_quote
*The is only _one_ HDF5 file format.*
#+end_quote

It is impossible to tell if a given HDF5 file was created by a sequential or
parallel application.

Notice that the example is a case of /weak scaling/: each process writes the same
amount of data, and the total amount of data written is proportional to the
number of processes. (We speak of /strong scaling/ when the total amount of data
written is kept constant, independent of the number of writing MPI processes.)

#+headers: :flags "-I./src" :libs -lhdf5 -lmpi
#+begin_src C -r -n :tangle src/phdf5-101.c :noweb no-export :exports code :results silent

#include "literate-hdf5.h"
#define SIZE 1024*1024

int main(int argc, char** argv)
{
  int size, rank;
  <<mpi-boilerplate>>

  {
    hid_t fapl, file, dset, file_space, mem_space;
    float* buffer;
    hsize_t file_size;

    fapl = H5Pcreate(H5P_FILE_ACCESS);
    H5Pset_fapl_mpio(fapl, MPI_COMM_WORLD, MPI_INFO_NULL); // (ref:par-fapl)
    file = H5Fcreate("multi-proc.h5", H5F_ACC_TRUNC, H5P_DEFAULT,
                     fapl); // (ref:par-fcrt)

    dset = (*
            <<make-dataset>>) (file, "xMi-floats", size*SIZE); // (ref:par-dcrt)
    file_space = H5Dget_space(dset);
    { // (ref:par-sel1)
      hsize_t start = rank*SIZE, count = 1, block = SIZE;
      H5Sselect_hyperslab(file_space, H5S_SELECT_SET,
                          &start, NULL, &count, &block);
    } // (ref:par-sel2)

    <<create-buffer-and-write>> // (ref:par-wrt)

    <<clean-up>>
  }

  MPI_Finalize(); // (ref:par-mpi-shutdown)
}

#+end_src

** Cloud

The best known example is the [[https://www.hdfgroup.org/solutions/highly-scalable-data-service-hsds/][Highly Scalable Data Service]] (HSDS). See John
Readey's [[https://www.youtube.com/watch?v=9b5TO7drqqE][presentation]].

*CAUTION:* To work with HDF5 in cloud-based environments means different things to
different audiences. Without context, it means just this:
#+begin_src plantuml :file img/cloud-hdf5.png :exports results
scale 2
cloud " HDF5 "
    #+end_src

    #+RESULTS:
    [[file:img/cloud-hdf5.png]]

*  Simple Data Analysis

*Reference:* [[https://www.youtube.com/watch?v=AP4LX8L7MFM][Reproducible Research with GNU Emacs and Org-mode]] by Thibault
Lestang

The following stochastic differential equation describes a [[https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process][1D
/Ornstein-Uhlenbeck/ process]]:

\begin{equation}
\mathrm{d}x_t = -\mu x_t + \sqrt{2D}\mathrm{d}W_t
\end{equation}

$\mu > 0$ and $D > 0$ are parameters and $W_t$ denotes the Wiener process.

** Simulation

A sample trajectory of the stochastic process can be approximated with a snippet
of C++ code.

#+NAME: initial_data
#+HEADER: :includes '("<iostream>" "<random>")
#+begin_src C++ :cache yes :noweb yes :results silent
std::default_random_engine generator;
std::normal_distribution<> distribution{0.0, 1.0};

double dt = 0.1, mu = 0.0, D = 0.5;

double x = 0.0;

for (unsigned i = 0; i < 100; ++i)
  {
    auto t = i*dt;
    auto dw = distribution(generator);
    x += (mu - x)*dt + sqrt(2.*D)*dw;
    std::cout << t << " " << x << std::endl;
  }
#+end_src

** Visualization<<sec:viz>>

#+HEADER: :var timeseries=initial_data :results file :dir "./img/"
#+begin_src python :exports both
import numpy as np, matplotlib.pyplot as plt

timeseries = np.array(timeseries)
fig = plt.figure()
plt.plot(timeseries[:,0], timeseries[:,1])
plt.subplot(111).set_xlabel('t')
plt.subplot(111).set_ylabel('x')
plt.savefig('timeseries_vis.png')
return 'timeseries_vis.png'
#+end_src

#+RESULTS:
[[file:img/timeseries_vis.png]]

** Statistics

The following function computes the sample mean.

#+NAME: mean
#+HEADER: :var x=0
#+begin_src python :exports code
from numpy import array, mean
values = array(x)[:,1]
return mean(values)
#+end_src

After a long and complicated statistical analysis, we conclude that the sample
average is call_mean(initial_data) {{{results(=-0.023857982999999992=)}}}.

** Storing the sample trajectory

The following snippet stores our sample as a =100 x 2= 2D array.

#+begin_src python :var x=initial_data :exports both
import h5py, numpy as np

with h5py.File('hello.hdf5', 'a') as f:
    f['t_x'] = np.array(x)
    return 'SUCCESS'
#+end_src

#+RESULTS:
: SUCCESS

#+begin_src sh :results output :exports both
h5dump -H -d t_x hello.hdf5
#+end_src

#+RESULTS:
: HDF5 "hello.hdf5" {
: DATASET "t_x" {
:    DATATYPE  H5T_IEEE_F64LE
:    DATASPACE  SIMPLE { ( 100, 2 ) / ( 100, 2 ) }
: }
: }

Except for the name of the dataset =t_x=, it may not be obvious who's who.

*** Field names

The following snippet stores our sample as a =100= element 1D array of a compound
datatype.

#+begin_src python :var x=initial_data  :exports both

import h5py, numpy as np

dt = np.dtype([("time", np.double), ("position", np.double)])
a = np.array(x)

with h5py.File('hello.hdf5', 'a') as f:
    f.create_dataset("compound", (100,), dtype=dt)
    f['compound'][:,'time'] = a[:,0]
    f['compound'][:,'position'] = a[:,1]
    return 'SUCCESS'

#+end_src

#+RESULTS:
: SUCCESS

#+begin_src sh :results output :exports both
h5dump -H -d compound hello.hdf5
#+end_src

#+RESULTS:
: HDF5 "hello.hdf5" {
: DATASET "compound" {
:    DATATYPE  H5T_COMPOUND {
:       H5T_IEEE_F64LE "time";
:       H5T_IEEE_F64LE "position";
:    }
:    DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }
: }
: }

* Creating a Self-Contained Package

** Setting attributes

Let's make this container more self-documenting by storing the simulation
parameters $\mathrm{d}t$, $D$, and $\mu$!

#+begin_src python :results silent

import h5py, numpy as np

with h5py.File('hello.hdf5', 'a') as f:
    dset = f["compound"]
    dset.attrs['dt'] = 0.1
    dset.attrs['D'] = 0.5
    dset.attrs['μ'] = 0.0

#+end_src

#+begin_src sh :results panel output :exports both
h5dump -A -d compound hello.hdf5
#+end_src

#+RESULTS:
#+begin_example
HDF5 "hello.hdf5" {
DATASET "compound" {
   DATATYPE  H5T_COMPOUND {
      H5T_IEEE_F64LE "time";
      H5T_IEEE_F64LE "position";
   }
   DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }
   ATTRIBUTE "D" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SCALAR
      DATA {
      (0): 0.5
      }
   }
   ATTRIBUTE "dt" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SCALAR
      DATA {
      (0): 0.1
      }
   }
   ATTRIBUTE "μ" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SCALAR
      DATA {
      (0): 0
      }
   }
}
}
#+end_example

Other good candidates for attributes include physical units, calibrations, RNG
seeds, etc.

** Image handling

In this section, we focus on /raster/ images. However, the two approaches
presented here apply, mutatis mutandis, to /vector/ images.

We can treat images as blobs or byte sequences (see the section [[sec:opaque][Opaque
datasets]]), or we cant treat them as 2D arrays of pixels/color values plus
certain metadata, e.g., palette (see the section [[sec:transparent][Annotated 2D
datasets]]). Whichever approach we choose determines how they then can be accessed
or manipulated.

*** Opaque datasets<<sec:opaque>>

#+header: :flags "-I./src" :libs -lhdf5
#+begin_src C -r -n :noweb no-export :tangle src/image2opaque.c :results output

#include "literate-hdf5.h"

int main(int argc, char** argv)
{
  size_t size;
  char* buf = (*
               <<read-image-bytes>>) ("./img/timeseries_vis.png", &size);
  printf("%ld\n", size);

  (*
   <<create-and-write-opaque-dset>>) ("hello.hdf5", "bytes", buf, size);

  free(buf);
  return 0;
}

  #+end_src

  #+RESULTS:
  : 32141

**** =<<read-image-bytes>>=

  #+begin_src C :noweb-ref read-image-bytes :exports code

lambda(char*, (const char* name, size_t* size),
       {
         char* result;
         FILE* fp = fopen(name, "rb");
         fseek(fp, 0L, SEEK_END);
         *size = ftell(fp);
         fseek(fp, 0, SEEK_SET);
         result = (char*) malloc(*size);
         fread(result, size, 1, fp);
         fclose(fp);
         return result;
       })

#+end_src

**** =<<create-and-write-opaque-dset>>=

#+begin_src C :noweb-ref create-and-write-opaque-dset :exports code

lambda(void,
       (const char* fname, const char* dname,
        const char* buf, size_t size),
       {
         hid_t file = H5Fopen(fname, H5F_ACC_RDWR, H5P_DEFAULT);
         hid_t dtype = H5Tcreate(H5T_OPAQUE, size);
         hid_t dspace = H5Screate(H5S_SCALAR);
         hid_t dset;
         H5Tset_tag(dtype, "image/png");
         dset = H5Dcreate(file, dname, dtype, dspace,
                          H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT);
         H5Dwrite(dset, dtype, H5S_ALL, H5S_ALL, H5P_DEFAULT, buf);
         H5Dclose(dset);
         H5Sclose(dspace);
         H5Tclose(dtype);
         H5Fclose(file);
       })

#+end_src

*** Annotated 2D datasets<<sec:transparent>>

We use a simple tool =gif2h5= to create a dataset representation conforming to
the [[https://portal.hdfgroup.org/display/HDF5/HDF5+Image+and+Palette+Specification%2C+Version+1.2][HDF5 image specification]]. As a sample image, we use the sample trajectory
from section [[sec:viz][Visualization]]. Unfortunately, the simple =gif2h5= tool accepts only
GIF images, and we need to first convert the PNG file =timeseries_vis.png=.
[[https://imagemagick.org/index.php][ImageMagick]] to the rescue!

#+begin_src sh :results output :exports both
convert -version
#+end_src

#+RESULTS:
: Version: ImageMagick 6.9.10-23 Q16 x86_64 20190101 https://imagemagick.org
: Copyright: © 1999-2019 ImageMagick Studio LLC
: License: https://imagemagick.org/script/license.php
: Features: Cipher DPC Modules OpenMP
: Delegates (built-in): bzlib djvu fftw fontconfig freetype heic jbig jng jp2 jpeg lcms lqr ltdl lzma openexr pangocairo png tiff webp wmf x xml zlib

#+begin_src sh :results silent
convert ./img/timeseries_vis.png timeseries_vis.gif
#+end_src

Now we are ready to call =gif2h5=.

#+begin_src sh :results silent
gif2h5 timeseries_vis.gif timeseries_vis.h5
#+end_src

=timeseries_vis.h5= contains a 2D dataset of pixels called =Image0= and a 2D
palette called =global=.

#+begin_src sh :results output :exports both
h5ls -v timeseries_vis.h5
#+end_src

#+RESULTS:
#+begin_example
Opened "timeseries_vis.h5" with sec2 driver.
Image0                   Dataset {480/480, 640/640}
    Attribute: CLASS scalar
        Type:      6-byte null-terminated ASCII string
    Attribute: IMAGE_SUBCLASS scalar
        Type:      14-byte null-terminated ASCII string
    Attribute: IMAGE_VERSION scalar
        Type:      4-byte null-terminated ASCII string
    Attribute: PALETTE scalar
        Type:      object reference
    Location:  1:1400
    Links:     1
    Storage:   307200 logical bytes, 307200 allocated bytes, 100.00% utilization
    Type:      native unsigned char
global                   Dataset {128/128, 3/3}
    Attribute: CLASS scalar
        Type:      8-byte null-terminated ASCII string
    Attribute: PAL_VERSION scalar
        Type:      4-byte null-terminated ASCII string
    Location:  1:800
    Links:     1
    Storage:   384 logical bytes, 384 allocated bytes, 100.00% utilization
    Type:      native unsigned char
#+end_example

Use [[https://portal.hdfgroup.org/display/HDFVIEW/HDFView][HDFView]] to look at the image!

Finally we copy the pixel and palette datasets to =hello.hdf5=.

#+begin_src sh :results panel output
h5copy -v -f ref -i timeseries_vis.h5 -s Image0 -o hello.hdf5 -d Image0
#+end_src

#+RESULTS:
: Copying file <timeseries_vis.h5> and object <Image0> to file <hello.hdf5> and object <Image0>
: Using ref flag

** Jamming a text file

Finally, we jam this text file (Org file)

#+NAME: org-file-name
#+begin_src emacs-lisp :results silent :exports none
buffer-file-name
#+end_src

#+begin_src sh :var ublock=org-file-name :results output verbatim :exports both
h5jam -i hello.hdf5 -u $ublock --clobber
head -n 10 hello.hdf5
#+end_src

#+RESULTS:
#+begin_example
,#+TITLE: HDF5 Introduction
,#+AUTHOR: Gerd Heber
,#+EMAIL: gheber@hdfgroup.org
,#+CREATOR: <a href="http://www.gnu.org/software/emacs/">Emacs</a> 27.1.90 (<a href="http://orgmode.org">Org</a> mode 9.4.4)
,#+DATE: [2021-01-01 Fri]
,#+OPTIONS: author:t creator:t email:t toc:nil num:nil

,#+PROPERTY: header-args :eval never-export

,* Outline
#+end_example

It's still an HDF5 file:

#+begin_src sh :results panel output :exports both
h5ls -vr hello.hdf5
#+end_src

#+RESULTS:
#+begin_example
Opened "hello.hdf5" with sec2 driver.
/                        Group
    Attribute: processor scalar
        Type:      variable-length null-terminated UTF-8 string
    Attribute: release scalar
        Type:      variable-length null-terminated UTF-8 string
    Attribute: system scalar
        Type:      variable-length null-terminated UTF-8 string
    Location:  1:96
    Links:     1
/15                      Group
    Location:  1:1344
    Links:     1
/15/temperature          Dataset {1024/1024}
    Attribute: dt scalar
        Type:      native double
    Location:  1:1072
    Links:     1
    Storage:   8192 logical bytes, 8192 allocated bytes, 100.00% utilization
    Type:      native double
/15/wind                 Dataset {2048/2048}
    Attribute: dt scalar
        Type:      native double
    Location:  1:14992
    Links:     1
    Storage:   16384 logical bytes, 16384 allocated bytes, 100.00% utilization
    Type:      native double
/Image0                  Dataset {480/480, 640/640}
    Attribute: CLASS scalar
        Type:      6-byte null-terminated ASCII string
    Attribute: IMAGE_SUBCLASS scalar
        Type:      14-byte null-terminated ASCII string
    Attribute: IMAGE_VERSION scalar
        Type:      4-byte null-terminated ASCII string
    Attribute: PALETTE scalar
        Type:      object reference
    Location:  1:381709
    Links:     1
    Storage:   307200 logical bytes, 307200 allocated bytes, 100.00% utilization
    Type:      native unsigned char
/bytes                   Dataset {SCALAR}
    Location:  1:40320
    Links:     1
    Storage:   32141 logical bytes, 32141 allocated bytes, 100.00% utilization
    Type:      32141-byte opaque type
               (tag = "image/png")
/compound                Dataset {100/100}
    Attribute: D scalar
        Type:      native double
    Attribute: dt scalar
        Type:      native double
    Attribute: \316\274 scalar
        Type:      native double
    Location:  1:36416
    Links:     1
    Storage:   1600 logical bytes, 1600 allocated bytes, 100.00% utilization
    Type:      struct {
                   "time"             +0    native double
                   "position"         +8    native double
               } 16 bytes
/t_x                     Dataset {100/100, 2/2}
    Location:  1:32768
    Links:     1
    Storage:   1600 logical bytes, 1600 allocated bytes, 100.00% utilization
    Type:      native double
/~obj_pointed_by_382077  Dataset {128/128, 3/3}
    Attribute: CLASS scalar
        Type:      8-byte null-terminated ASCII string
    Attribute: PAL_VERSION scalar
        Type:      4-byte null-terminated ASCII string
    Location:  1:382077
    Links:     2
    Storage:   384 logical bytes, 384 allocated bytes, 100.00% utilization
    Type:      native unsigned char
#+end_example

We can extract the so-called /user block/ at the beginning of the file with =h5unjam=:

#+begin_src sh :results silent :exports code
h5unjam -i hello.hdf5 -o no-user-block.h5 -u user-block.org
#+end_src

#+begin_src sh :results output
head -n 10 user-block.org
#+end_src

#+RESULTS:
#+begin_example
,#+TITLE: HDF5 Introduction
,#+AUTHOR: Gerd Heber
,#+EMAIL: gheber@hdfgroup.org
,#+CREATOR: <a href="http://www.gnu.org/software/emacs/">Emacs</a> 27.1.90 (<a href="http://orgmode.org">Org</a> mode 9.4.4)
,#+DATE: [2021-01-01 Fri]
,#+OPTIONS: author:t creator:t email:t toc:nil num:nil

,#+PROPERTY: header-args :eval never-export

,* Outline
#+end_example

* Appendix <<sec:appendix>>

** Boilerplate and common code <<sec:boilerplate>>

In this section, we provide the common code snippets for the [[sec:hpc][sequential and
parallel examples]].

*** =<<mpi-boilerplate>>=

This typical MPI boilerplate. Each MPI process determines the communicator size
and its own rank.

#+begin_src C -r -n :noweb-ref mpi-boilerplate

MPI_Init(&argc, &argv);
MPI_Comm_size(MPI_COMM_WORLD, &size);
MPI_Comm_rank(MPI_COMM_WORLD, &rank);

#+end_src

*** =<<make-dataset>>=

To create a dataset (array variable) we need to specify its shape (line [[(dsp-crt)]]) and the
datatype of its elements (~H5T_IEEE_F32~ on line [[(dst-crt)]]).

#+begin_src C -r -n :noweb-ref make-dataset

lambda(hid_t, (hid_t file, const char* name, hsize_t elt_count),
       {
         hid_t result;
         hid_t fspace = H5Screate_simple(1, (hsize_t[]) { elt_count },
                                         NULL); // (ref:dsp-crt)
         result = H5Dcreate(file, name, H5T_IEEE_F32LE, fspace,
                            H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT); // (ref:dst-crt)
         H5Sclose(fspace);
         return result;
       })

#+end_src

*** =<<create-buffer-and-write>>=

We create and initialize the data buffer to be written. Its shape is described
by its in-memory dataspace ~mem_space~ (line [[(msp)]]). Since we are writing the
entire buffer, we are selecting all elements (line [[(msp-sel)]]).

#+begin_src C -r -n :noweb-ref create-buffer-and-write

buffer = (float*) malloc(SIZE*sizeof(float));
{ /* Do something interesting with buffer! */
  size_t i;
  for (i = 0; i < SIZE; ++i)
    buffer[i] = (float) i;
}

mem_space = H5Screate_simple(1, (hsize_t[]) { SIZE }, NULL); // (ref:msp)
H5Sselect_all(mem_space); // (ref:msp-sel)

H5Dwrite(dset, H5T_NATIVE_FLOAT, mem_space, file_space, H5P_DEFAULT,
         buffer);

#+end_src

*** =<<clean-up>>=

Adhering to the HDF5 library's handle discipline is the A and $\Omega$ when
working with the C-API. All resources acquired in the course of an application
must be released eventually.

#+begin_src C -r -n :noweb-ref clean-up

H5Pclose(fapl);
free(buffer);
H5Sclose(mem_space);
H5Sclose(file_space);
H5Dclose(dset);
H5Fclose(file);

#+end_src

* COMMENT Local Variables

# Local Variables:
# org-html-head: "<link rel=\"stylesheet\" type=\"text/css\" href=\"css/stylesheet.css\" />"
# org-coderef-label-format: "// (ref:%s)"
# End:
